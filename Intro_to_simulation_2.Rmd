---
title: "Introduction to simulation, Part 2"
author: "Put your name here"
date: "Put the date here"
output: pdf_document
---
<!-- Please don't mess with the next two lines! -->
\newenvironment{answer}{\definecolor{shadecolor}{RGB}{225, 225, 255}\begin{shaded}}{\end{shaded}}
<!-- Please don't mess with the previous two lines! -->


## Introduction

In this module, we'll learn more about simulation and randomization. Instead of flipping coins, in this assignment we'll randomly shuffle our data around in order to explore the effects of randomizing an explanatory variable.


## Instructions

Presumably, you have already created a new project and downloaded this file into it. Please knit the document and work back and forth between this R Markdown file and the PDF output as you work through this module.

When you are finished with the assignment, knit to PDF one last time, proofread the PDF file **carefully**, export the PDF file to your computer, and then submit your assignment.

Sometimes you will be asked to add your own R code. That will appear in this document as a code chunk with a request for you to add your own code, like so:

```{r}
## Add code here to [do some task]...
```

Be sure to remove the line `## Add code here to [do some task]...` when you have added your own code.

Sometimes you will be asked to type up your thoughts. That will appear in the document as follows:

\begin{answer}
Please write up your answer here.
\end{answer}

Again, please be sure to remove the line "Please write up your answer here" when you have written up your answer. In these areas of the assignment, please use contextually meaningful full sentences/paragraphs (unless otherwise indicated) and proper spelling, grammar, punctuation, etc. This is not R code, but rather a free response section where you talk about your analysis and conclusions. If you need to use some R code as well, you can use inline R code inside the block between `\begin{answer}` and `\end{answer}`, or if you need an R code chunk, please go outside the `answer` block and start a new code chunk.


## Load Packages

We load the `MASS` package to access the `birthwt` data on risk factors associated with low birth weight. We also load the `mosaic` package for simulation tools and the `gmodels` package for nice contingency tables using the `CrossTable` command.

```{r, warning = FALSE, message=FALSE}
library(MASS)
library(mosaic)
library(gmodels)
```

As explained in an earlier module, we will set the seed so that our results are reproducible.

```{r}
set.seed(3141593)
```

## Our research question

We are interested in finding out if there is an association between smoking during pregnancy and low birth weight. We'll use the birth weight data `birthwt` from the `MASS` package.


## Exploratory data analysis

Rather than using the actual birth weight of the baby (we'll do that in a future assignment), let's use the categorical variable `low` that is simply an indicator (yes/no) of whether the birth weight is less than 2.5 kg.

We can see below that neither `smoke` nor `low` are factor variables as we need them to be:

```{r}
str(birthwt)
```

We'll fix that by creating new factor variables called `smoke` and `low` and putting them in their own data frame.

**An important note about the order of the levels and labels in a factor variable:**

In a categorical variable (called a "factor" variable in R), the order of the categories usually does not matter. However, in statistics, we often designate one category as the "success" category, or the category of interest to us. All other categories are considered "failures". For example, if I want to measure the proportion of mothers who smoke, then those mothers who are smokers are considered "successes". Likewise, it is the low birth weight babies who are of interest to us; therefore a "Yes" in this variable will be considered a "success". The terminology is unfortunate, but we're stuck with it.

In the `factor` command in R, be sure to list the success category first in both the `level` and `label` part of the command. We want to measure the mothers who smoke. Furthermore, we are interested in whether those mothers have babies with low birth weight, so (unfortunately) having low birth weight is considered the "success" condition. Observe the ordering of the levels and labels in the following:

```{r}
smoke <- factor(birthwt$smoke, levels = c(1, 0), labels = c("Yes", "No"))
low <- factor(birthwt$low, levels = c(1, 0), labels = c("Yes", "No"))
smoke_low <- data.frame(smoke, low)
```

### Exercise

Create a contingency table with `smoke` as the row variable and `low` as the column variable with only counts and row percentages displayed. (In other words, use the extra options in the `CrossTable` command to get rid of all the extra cruft that appears by default.) Go back to the R module `Tables.Rmd` if you need to review the `CrossTable` command.

```{r}
## Add code here to create a contingency table with smoke as the 
## row variable and low as the column variable. 
```

By placing `smoke` as the row variable and `low` as the column variable, and then looking at row percentages, we are implying that one variable is explanatory and one is response. Which variable are we treating as explanatory and which are we treating as response? Do you agree with that choice? Why or why not?

\begin{answer}
Please write up your answer here.
\end{answer}

*****

Although we can read off the percentages in the contingency table, we need a command to extract the proportions for use in further calculations. One way is via the `prop` command. This command uses the "tilde" notation. The variable on the left of the tilde (`low`) is the variable of interest, and we're dividing up the data into groups based on the variable on the right of the tilde (`smoke`). You can remember this by thinking, "Calculate low birth weight **by** smoking status." Note that this is backwards from the order we used in the `CrossTable` command.

```{r}
prop(low ~ smoke, data = smoke_low)
```

The column headers in the resulting output are a bit opaque. What we have here are the two percentages of interest that we're trying to compare.

### Exercise

Interpret these percentages in the context of the data. In other words, what do these percentages say about the women who do not smoke during pregnancy versus the women who do? (Hint: look back at the contingency table you made earlier. Where do these percentages come from?)

\begin{answer}
Please write up your answer here.
\end{answer}

*****

The real statistic of interest to us, though, is the difference between these percentages. We can use the `diffprop` function from the `mosaic` package.

```{r}
diffprop(low ~ smoke, data = smoke_low)
```

Let's store this value for future use. We can use any name we want, but I've chosen `obs_diff` here for "observed difference".

```{r}
obs_diff <- diffprop(low ~ smoke, data = smoke_low)
obs_diff
```

### Exercise

In which order are the groups being subtracted? In other words, why is the observed difference negative?

\begin{answer}
Please write up your answer here.
\end{answer}

*****

## Shuffling

One way to see if there is evidence of an association between smoking and low birth weight is to assume, temporarily, that there is no association. If there is truly no association, then the difference between the non-smoking group and the smoking group should be 0%.

Now, we saw a difference of `r 100*obs_diff`% between the two groups in the data. Then again, non-zero differences can just come about by pure chance alone. We may have accidentally sampled more smokers who also just happened to have babies with low birth weight, even if there were no association in general.

So how do we test the range of values that could arise from just chance alone? In other words, how do we explore sampling variability?

One way to force the variables to  be independent is to "shuffle" the values of `smoke`. If instead of measuring whether women actually smoke or not, we just randomly and arbitrarily label them as "smokers" or "non-smokers" (independent of their *actual* smoking status), we know for sure that such an assignment is random and not due to any actual evidence of smoking. In that case, low birth weight babies are equally likely to occur in both groups.

Let's see how shuffling works in R. To begin with, we look at the first 20 actual values of `smoke` in our data.

```{r}
head(smoke_low$smoke, 20)
```

Now we "shuffle" all the values around and look at the first 20 again:

```{r}
head(shuffle(smoke_low$smoke), 20)
```

Do it again, just to make sure it's random:

```{r}
head(shuffle(smoke_low$smoke), 20)
```


## Simulation

The idea here is to keep the low birth weight status the same for each woman, but randomly shuffle the smoking labels. There will still be the same number of women who "smoke", but now they will be randomly assigned such a designation. Since this new grouping into "smoking" and "non-smoking" is completely random and arbitrary, we expect the likelihood of having a low birth weight baby to be equal for both groups.

A more precise way of saying this is that the expected difference under the assumption of independent variables is 0%. If there were truly no association, then the percentage of women having low birth weight babies would be independent of smoking. However, sampling variability means that we are not likely to see an exact difference of 0%. In fact, due to the sample sizes in each group, it is impossible to get a difference of exactly 0%. The real question, then, is how different could the difference be from 0% and still be reasonably possible due to random chance.

Here are a few random simulations. (The randomness is built into the `shuffle` command.)

```{r}
diffprop(low ~ shuffle(smoke), data = smoke_low)
diffprop(low ~ shuffle(smoke), data = smoke_low)
diffprop(low ~ shuffle(smoke), data = smoke_low)
```

The `do` command from the `mosaic` package allows us to repeat this simulation process any number of times. From an earlier module, we learned that the number of simulations needs to be sufficiently high to make sure we have a good representative set of outcomes. The results will be gathered together in a data frame that we will call `sims`.

```{r}
sims <- do(5000) * diffprop(low ~ shuffle(smoke), data = smoke_low)
head(sims, 20)
```


## Plot results

A histogram will show us the range of possible values under the assumption of independence of the two variables. On the same plot, we graph a line at the value of the observed difference in proportions to see if that value could have reasonably occurred by chance alone.

```{r}
ggplot(sims, aes(x = diffprop)) +
    geom_histogram(binwidth = 0.05) +
    geom_vline(xintercept =  obs_diff, color = "blue")
```

### Exercise

Why is the mode of the graph above at 0? This has been explained several different times in this module, but put it into your own words to make sure you understand the logic behind the shuffling.

*****


## By chance?

How likely is it that the observed difference (or a difference even more extreme) could have resulted from chance alone? Because `sims` contains simulated results after shuffling, the variable `diffprop` contains values that assume that smoking is independent of birth weight. In order to assess how plausible our observed difference is under that assumption, we want to find out how many of the simulated values are at least as small, if not smaller, than the observed difference, `r obs_diff`. We can do this using the same `prop` command we saw before, but used in a slightly different way. In the command below, we put the condition

`sims$diffprop <= obs_diff`.

In other words this is asking, "When is the value of `diffprop` less than or equal to the difference that was actually observed in our data?"

```{r}
prop(sims$diffprop <= obs_diff)
```

What is this telling us? Well, this percentage is small. This shows us that if there were truly no association between smoking and low birth weight, then our data is a rare event. (An observed difference this extreme or more extreme would only occur `r 100 * prop(sims$diffprop <= obs_diff)`% of the time.)

Because the probability above is so small, it seems unlikely that our variables are independent. Therefore, it seems more likely that there is an association between smoking and low birth weight. We have evidence of a statistically significant difference between the chance of having a baby with low birth weight among women who smoke versus women who don't smoke.

Keep in mind that this data is from an observational study, so we cannot conclude that smoking *causes* low birth weight. All we can say is that a difference of `r 100*obs_diff`% is evidence that mothers who smoke are more likely to have babies with low birth weight for **some** reason (maybe because they smoke, but maybe some other reason).

### Exercise

When we see an association between two variables, it may be that both factors are related to some third variable that we haven't measured. When that happens, that third variable is called a *lurking variable*. Get creative for a minute and see if you can come up with a reasonably plausible lurking variable for the scenario above. In other words, if smoking itself doesn't cause low birth weight babies, can you imagine another factor that would cause low birth weight babies and also be associated with mothers smoking?

\begin{answer}
Please write up your answer here.
\end{answer}

*****

The point of the above exercise is not to convince people that smoking during pregnancy is not actually the cause of low birth weight babies. In fact, there is quite a bit of evidence that smoking during pregnancy causes all sorts of problems, including low birth weight.^[See this for example: http://www.ncbi.nlm.nih.gov/pubmed/16323070] However, **association is not causation**. From observational data like this, it is generally impossible to prove a causal relationship. I'm not saying there is never a causal relationship, only that you can't *prove* it from the analysis we did. Nevertheless, there is a clear association between smoking during pregnancy and low birth weight. Make sure you understand the difference.

### Your turn

Walk through the following sequence of steps to explore whether the presence of uterine irritability is associated with low birth weight. You should carefully copy and paste commands from earlier in the module, making the necessary changes to the variable names.

Uterine irritability is recorded in the variable `ui` in the `birthwt` data set.

1. Convert `ui` to a factor variable, paying careful attention to the assignment of the levels and labels. (Which condition is considered a "success" here?) Then create a new data frame from the factor variables `ui` and `low`. (As `low` is already a factor variable, you don't need to re-do the work for that one.)

```{r}
## Add code here to convert ui to a factor variable
## and combine ui and low into a single data frame.
```

2. Exploratory data analysis: make a contingency table with `ui` and `low`. You will need to decide which variable is explanatory and which is response, and assign the two variables to the rows and columns accordingly. Don't forget to use row percentages.

```{r}
## Add code here to make a contingency table.
```

3. Use the `diffprop` function to calculate and store the observed difference in the proportion of low birth weight babies between women with and without uterine irritability.

```{r}
## Add code here to calculate the observed difference.
```

4. Simulate 2000 outcomes under the assumption that low birth weight is independent of uterine irritability. Use the `do` command in conjunction with `diffprop` and `shuffle` in a single line of code.

```{r}
## Add code here to simulate 2000 outcomes under the independence assumption.
```

5. Plot the simulated values in a histogram. Be sure to include a vertical line at the value of the observed difference.

```{r}
## Add code here to plot the results.
```

6. Calculate how likely it is to see our observed difference or something even more extreme among the randomly simulated values.

```{r}
## Add code here to calculate how likely it is to see 
## our observed difference or something even more extreme 
## among the randomly simmulated values.
```

Finally, comment on what you see. Based on the number you get in step 6 above, is the observed difference rare? In other words, under the assumption that uterine irritability and low birth weight are independent, are we likely to see an observed difference as far away from zero as we actually see in the data? So what is your conclusion then? Do you believe there is an association between uterine irritability and low birth weight?

\begin{answer}
Please write up your answer here.
\end{answer}

*****

## Conclusion

Here we used simulation to explore the idea of two variable being independent or associated. When we assume they are independent, we can explore the sampling variability of the differences that occur by pure chance alone. We expect the difference to be zero, but we know that randomness will cause the simulated differences to have a range of values. Is the difference in the observed data far away from zero? In that case, we can say we have evidence that the variables are not independent; in other words, it is more likely that our variables are associated.


